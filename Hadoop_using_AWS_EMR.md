# To Create and Delete folder in Hadoop Using AWS EMR

## Steps to be followed:

### 1. View the hdfs dfs Command 
![step1](https://user-images.githubusercontent.com/63596869/85577989-57393b80-b657-11ea-8422-550d3bfb6b37.jpg)

### 2. Create a Directory in HDFS
![step4 ](https://user-images.githubusercontent.com/63596869/85578828-0118c800-b658-11ea-8947-d4cbccb7cf0c.jpg)

### 3. Delete a Directory
![Inkedstep6_LI](https://user-images.githubusercontent.com/63596869/85579973-f579d100-b658-11ea-9e5e-450585cb1514.jpg)

### 4. Download the file in AWS EMR and Unzip it
![step7](https://user-images.githubusercontent.com/63596869/85580621-8486e900-b659-11ea-8a8d-0c2b55ce571f.jpg)
![step8](https://user-images.githubusercontent.com/63596869/85580643-894b9d00-b659-11ea-91de-62543d5935a3.jpg)

### 5. Upload a File to HDFS and 
![step9](https://user-images.githubusercontent.com/63596869/85582955-7a65ea00-b65b-11ea-8997-5034a0808955.jpg)
> Run the following -put command to copy data.txt into the test folder in HDFS: 

### 6. Copy a File in HDFS 
![step10](https://user-images.githubusercontent.com/63596869/85583317-c87aed80-b65b-11ea-9eb1-54ccef6616b2.jpg)

### 7. View the Contents of a File in HDFS 
-  You can use the -cat command to view text files in HDFS.
![step11](https://user-images.githubusercontent.com/63596869/85583718-20195900-b65c-11ea-8c20-27cb2b85e8dc.jpg)
- You can also use the ‚Äêtail command to view the end of a file: 
![step12](https://user-images.githubusercontent.com/63596869/85583826-39220a00-b65c-11ea-938e-41ae853422c9.jpg)

### 8. Final step
![final step](https://user-images.githubusercontent.com/63596869/85583962-58209c00-b65c-11ea-8cce-b56b1bcd7e4f.jpg)


*We have created and deleted the folder in Hadoop using AWS EMR.*